{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hult Internation Business School \n",
    "Assignment: Individual Regression Assignment\n",
    "Student   : Mosiuwa Tshabalala\n",
    "Subject   : Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the relevant packages for data science essentials, modeling and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "ac_dataset = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Removing outliers using standard deviation detection\n",
    "mean = ac_dataset['TOTAL_PHOTOS_VIEWED'].mean()\n",
    "std = ac_dataset['TOTAL_PHOTOS_VIEWED'].std()\n",
    "cut_off = std * 3\n",
    "lower, upper = mean - cut_off, mean + cut_off\n",
    "new_acdata = ac_dataset[(ac_dataset['TOTAL_PHOTOS_VIEWED'] < upper) & (ac_dataset['TOTAL_PHOTOS_VIEWED'] > lower)]\n",
    "\n",
    "mean = ac_dataset['AVG_TIME_PER_SITE_VISIT'].mean()\n",
    "std = ac_dataset['AVG_TIME_PER_SITE_VISIT'].std()\n",
    "cut_off = std * 3\n",
    "lower, upper = mean - cut_off, mean + cut_off\n",
    "new_acdata = ac_dataset[(ac_dataset['AVG_TIME_PER_SITE_VISIT'] < upper) & (ac_dataset['AVG_TIME_PER_SITE_VISIT'] > lower)]\n",
    "\n",
    "mean = ac_dataset['CONTACTS_W_CUSTOMER_SERVICE'].mean()\n",
    "std = ac_dataset['CONTACTS_W_CUSTOMER_SERVICE'].std()\n",
    "cut_off = std * 3\n",
    "lower, upper = mean - cut_off, mean + cut_off\n",
    "new_acdata = ac_dataset[(ac_dataset['CONTACTS_W_CUSTOMER_SERVICE'] < upper) & (ac_dataset['CONTACTS_W_CUSTOMER_SERVICE'] > lower)]\n",
    "\n",
    "mean = ac_dataset['AVG_PREP_VID_TIME'].mean()\n",
    "std = ac_dataset['AVG_PREP_VID_TIME'].std()\n",
    "cut_off = std * 3\n",
    "lower, upper = mean - cut_off, mean + cut_off\n",
    "new_acdata = ac_dataset[(ac_dataset['AVG_PREP_VID_TIME'] < upper) & (ac_dataset['AVG_PREP_VID_TIME'] > lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Combining columns that measure the same variable \n",
    "ac_dataset['Total_Deliveries'] = ac_dataset['LATE_DELIVERIES'] + ac_dataset['EARLY_DELIVERIES']\n",
    "ac_dataset['Total_Cancellations'] = ac_dataset['CANCELLATIONS_AFTER_NOON'] + ac_dataset['CANCELLATIONS_BEFORE_NOON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Initializing the split of email domains\n",
    "placeholder_lst = []\n",
    "\n",
    "for index, col in ac_dataset.iterrows(): \n",
    "    split_email = ac_dataset.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "email_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Creating the email dataframe, indexing & showing counts \n",
    "ac_email = pd.read_excel(file)\n",
    "\n",
    "email_df.columns = ['0', 'Personal_EMAIL']\n",
    "\n",
    "ac_email = pd.concat([ac_email, email_df['Personal_EMAIL']]\n",
    "                     , axis = 1)\n",
    "\n",
    "ac_email.loc[: , 'Personal_EMAIL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Feature Engineering: Processing the domains and assigning different groups for correlation analysis\n",
    "personal_email_domains = ['@gmail.com', '@qq.com', '@yahoo.com', '@protonmail.com','@hotmail.com','@live.com','@aol.com']\n",
    "professional_email_domains = ['@passport.com', '@intel.com', '@homedepot.com', '@goldmansacs.com', '@cisco.com', '@unitedtech.com', \n",
    "                              '@jpmorgan.com', 'pfizer.com', 'visa.com','@walmart.com','@disney.com','@pg.com','@caterpillar.com','@mmm.com',\n",
    "                              '@verizon.com','@boeing.com','@exxon.com','@travelers.com','@unitedhealth.com','@microsoft.com',\n",
    "                              '@chevron.com','@ibm.com','@dupont.com','@ge.org','@apple.com','@nike.com','@mcdonalds.com',\n",
    "                             '@jnj.com','@merck.com', '@cocacola.com','@amex.com']\n",
    "fake_email_domains = ['@me.com','@msn.com', '@passport.com']\n",
    "\n",
    "placeholder_lst = []\n",
    "\n",
    "for domain in ac_email['Personal_EMAIL']:\n",
    "    \n",
    "        if '@' + domain in personal_email_domains:\n",
    "            placeholder_lst.append('Personal')\n",
    "\n",
    "        elif '@' + domain in professional_email_domains:\n",
    "            placeholder_lst.append('Professional')\n",
    "            \n",
    "        elif '@' + domain in fake_email_domains:\n",
    "            placeholder_lst.append('Fake')\n",
    "\n",
    "        else:\n",
    "                'Unknown'\n",
    "        \n",
    "ac_email['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "ac_email['domain_group'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Using one hot encoding to create columns and merging new columns into the original dataset\n",
    "oh_email = pd.get_dummies(ac_email['domain_group'])\n",
    "\n",
    "ac_email = ac_email.drop('domain_group', axis = 1)\n",
    "\n",
    "ac_email = ac_email.join([oh_email])\n",
    "\n",
    "ac_email = ac_dataset.drop(['EMAIL'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transforming Revenue and saving it to the dataset\n",
    "ac_dataset['log_Revenue'] = np.log10(ac_dataset['REVENUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping categorical variables after they've been encoded or processed\n",
    "ac_dataset = ac_dataset.drop('NAME', axis = 1)\n",
    "ac_dataset = ac_dataset.drop('FAMILY_NAME', axis = 1)\n",
    "ac_dataset = ac_dataset.drop('FIRST_NAME', axis = 1)\n",
    "ac_dataset = ac_dataset.drop('EMAIL', axis = 1)\n",
    "ac_dataset = ac_dataset.drop('CANCELLATIONS_BEFORE_NOON', axis = 1)\n",
    "ac_dataset = ac_dataset.drop('CANCELLATIONS_AFTER_NOON', axis = 1)\n",
    "ac_dataset = ac_dataset.drop('EARLY_DELIVERIES', axis = 1)\n",
    "ac_dataset = ac_dataset.drop('LATE_DELIVERIES', axis = 1)\n",
    "\n",
    "print(ac_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing model\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Processing the Lasso Model to fit, split & create predictions \n",
    "ac_target = ac_dataset.loc[ : , 'log_Revenue']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                ac_dataset,\n",
    "                ac_target,\n",
    "                test_size = 0.25,\n",
    "                random_state = 219)\n",
    "\n",
    "lasso_model = sklearn.linear_model.Lasso(alpha = 0.000000008, normalize = True)\n",
    "\n",
    "lasso_fit = lasso_model.fit(x_train, y_train)\n",
    "\n",
    "lasso_pred = lasso_fit.predict(x_test)\n",
    "\n",
    "print('Lasso Training Score :', lasso_model.score(x_train, y_train).round(4))\n",
    "print('Lasso Testing Score :', lasso_model.score(x_test, y_test).round(4))\n",
    "\n",
    "lasso_train_score = lasso_model.score(x_train, y_train).round(4)\n",
    "lasso_test_score =  lasso_model.score(x_test, y_test).round(4)\n",
    "\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_values = zip(ac_dataset.columns, lasso_fit.coef_.round(decimals = 2))\n",
    "\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coeff_sum = 0\n",
    "for feature, coefficient in lasso_model_lst:\n",
    "    lasso_coeff_sum += coefficient\n",
    "    if coefficient == 0:\n",
    "        lasso_model_lst.remove((feature, coefficient))\n",
    "        \n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Processing the ARD Model to fit, split & create predictions \n",
    "ard_model = sklearn.linear_model.ARDRegression(normalize = False)\n",
    "\n",
    "ard_fit = ard_model.fit(x_train, y_train)\n",
    "\n",
    "ard_predict = ard_fit.predict(x_test)\n",
    "\n",
    "print('Training Score:', ard_model.score(x_train, y_train).round(4))\n",
    "print('Test Score:', ard_model.score(x_test, y_test).round(4))\n",
    "\n",
    "ard_train_score = ard_model.score(x_train, y_train).round(4)\n",
    "ard_test_score =  ard_model.score(x_test, y_test).round(4)\n",
    "\n",
    "print('ARD Train-Test Gap :', abs(ard_train_score - ard_test_score).round(4))\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ard_model_values = zip(ac_dataset.columns, ard_fit.coef_.round(decimals = 5))\n",
    "\n",
    "ard_model_lst = [('intercept', ard_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "for val in ard_model_values:\n",
    "    ard_model_lst.append(val)\n",
    "    \n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ard_coeff_sum = 0\n",
    "for feature, coefficient in ard_model_lst:\n",
    "    ard_coeff_sum +=coefficient \n",
    "    if coefficient == 0:\n",
    "        ard_model_lst.remove((feature, coefficient))\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Processing the OLS Model to fit, & presenting results \n",
    "lm_OLS = smf.ols(formula = \"\"\"  log_Revenue ~ TOTAL_PHOTOS_VIEWED  +\n",
    "                                                  TOTAL_MEALS_ORDERED  +\n",
    "                                                  UNIQUE_MEALS_PURCH +\n",
    "                                                  CONTACTS_W_CUSTOMER_SERVICE +\n",
    "                                                  AVG_PREP_VID_TIME \n",
    "                            \"\"\",\n",
    "                        data = ac_dataset)\n",
    "\n",
    "\n",
    "# telling Python to FIT the data to the blueprint\n",
    "results = lm_OLS.fit()\n",
    "\n",
    "\n",
    "# printing a summary of the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Processing the KNN model creating the scaled dataframe\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(ac_dataset)\n",
    "\n",
    "x_scaled = scaler.transform(ac_dataset)\n",
    "\n",
    "x_scaled_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "x_scaled_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_knn, x_test_knn, y_train_knn, y_test_knn = train_test_split(\n",
    "                x_scaled,\n",
    "                ac_target,\n",
    "                test_size = 0.25,\n",
    "                random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists for training set accuracy and test set accuracy\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "neighbors_settings = range(1, 21)\n",
    "\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "    clf.fit(x_train_knn, y_train_knn)\n",
    "    \n",
    "    training_accuracy.append(clf.score(x_train_knn, y_train_knn))\n",
    "    \n",
    "    test_accuracy.append(clf.score(x_test_knn, y_test_knn))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy,     label = \"test accuracy\")\n",
    "plt.ylabel(\"Accuracy of Model\")\n",
    "plt.xlabel(\"n_neighbors optimal spread\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the model \n",
    "knn_stand = KNeighborsRegressor(algorithm = 'auto',\n",
    "                                n_neighbors = 19)\n",
    "\n",
    "knn_stand_fit = knn_stand.fit(x_train_knn, y_train_knn)\n",
    "\n",
    "knn_stand_pred = knn_stand_fit.predict(x_test_knn)\n",
    "\n",
    "print('KNN Training Score:', knn_stand.score(x_train_knn, y_train_knn).round(4))\n",
    "print('KNN Testing Score :',  knn_stand.score(x_test_knn, y_test_knn).round(4))\n",
    "\n",
    "knn_stand_score_train = knn_stand.score(x_train_knn, y_train_knn).round(4)\n",
    "knn_stand_score_test  = knn_stand.score(x_test_knn, y_test_knn).round(4)\n",
    "\n",
    "print('KNN Train-Test Gap:', abs(knn_stand_score_train - knn_stand_score_test).round(4))\n",
    "knn_stand_test_gap = abs(knn_stand_score_train - knn_stand_score_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Model Type   Training Score\\tTesting Score\\tTrain-Test Gap\\tModel Size\\tModel Coefficients\\tFinal Chosen Model  \n",
    "========================================================================================================================\n",
    "Lasso        {lasso_train_score}\\t\\t{lasso_test_score}\\t\\t{lasso_test_gap}\\t\\t{len(lasso_model_lst)}\\t\\t{lasso_coeff_sum}\\t\\t\\t \"No\"\n",
    "ARD          {ard_train_score}\\t\\t{ard_test_score}\\t\\t{ard_test_gap}\\t\\t{len(ard_model_lst)}\\t\\t{ard_coeff_sum}\\t\\t\\t \"No\"\n",
    "*KNN*        {knn_stand_score_train} \\t\\t{knn_stand_score_test}\\t\\t{knn_stand_test_gap}\\t\\t\"NA\"\\t\\t\"NA\"\\t\\t\\t \"Yes\"\n",
    "OLS          \"NA\"\\t\\t\"0.575\"\\t\\t\" NA\"\\t\\t\"NA\"\\t\\t\"6 Variables\"\\t\\t \"No\"\n",
    "\n",
    "Based on the model performance we have decided to choose the KNN as our most \n",
    "optimal model. The Lasso and ARD models show a high testing score but seem too\n",
    "good to be true and could possibly signal overfitting of the model.  \n",
    "The KNN has been optimized through the neighbors settings feature.\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
